{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Train a simple deep CNN on the CIFAR10 small images dataset.\n",
    "\n",
    "It gets to 75% validation accuracy in 25 epochs, and 79% after 50 epochs.\n",
    "(it's still underfitting at that point, though).\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import os, glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "num_classes = 2\n",
    "epochs = 100\n",
    "data_augmentation = True\n",
    "num_predictions = 20\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_cifar10_trained_model.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# The data, split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (65, 32, 32, 3)\n",
      "65 train samples\n",
      "33 test samples\n"
     ]
    }
   ],
   "source": [
    "# フォルダの中にある画像を順次読み込む\n",
    "# カテゴリーは0から始める\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "path = 'C:/Users/shihnkawa/Pictures/ダウンロード/'\n",
    "\n",
    "# 対象Aの画像\n",
    "for picture in glob.glob(path+'whale/*.???'):\n",
    "    img = img_to_array(load_img(picture, target_size=(32,32)))\n",
    "    X.append(img)\n",
    "\n",
    "    Y.append(0)\n",
    "\n",
    "\n",
    "# 対象Bの画像\n",
    "for picture in glob.glob(path+'apple/*.???'):\n",
    "    img = img_to_array(load_img(picture, target_size=(32,32)))\n",
    "    X.append(img)\n",
    "\n",
    "    Y.append(1)\n",
    "\n",
    "\n",
    "# arrayに変換\n",
    "X = np.asarray(X)\n",
    "Y = np.asarray(Y)\n",
    "\n",
    "# 画素値を0から1の範囲に変換\n",
    "X = X.astype('float32')\n",
    "X = X / 255.0\n",
    "\n",
    "# クラスの形式を変換\n",
    "Y = np_utils.to_categorical(Y, 2)\n",
    "\n",
    "# 学習用データとテストデータ\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=111)\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_21 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 2)                 1026      \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 1,246,754\n",
      "Trainable params: 1,246,754\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using real-time data augmentation.\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 5s 570ms/step - loss: 1.8268 - acc: 0.2969 - val_loss: 0.9263 - val_acc: 0.5152\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 3s 375ms/step - loss: 1.0669 - acc: 0.2376 - val_loss: 0.8107 - val_acc: 0.3333\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 3s 426ms/step - loss: 0.8217 - acc: 0.3643 - val_loss: 0.6926 - val_acc: 0.5758\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 3s 377ms/step - loss: 0.6905 - acc: 0.4593 - val_loss: 0.6550 - val_acc: 0.7273\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 3s 381ms/step - loss: 0.6994 - acc: 0.6199 - val_loss: 0.5678 - val_acc: 0.8788\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 3s 418ms/step - loss: 0.6181 - acc: 0.7286 - val_loss: 0.5296 - val_acc: 0.9394\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 4s 494ms/step - loss: 0.5116 - acc: 0.8258 - val_loss: 0.5076 - val_acc: 0.7879\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 3s 383ms/step - loss: 0.4379 - acc: 0.8416 - val_loss: 0.3492 - val_acc: 0.9394\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 3s 402ms/step - loss: 0.3558 - acc: 0.8891 - val_loss: 0.5479 - val_acc: 0.6364\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 5s 574ms/step - loss: 0.3422 - acc: 0.8594 - val_loss: 0.2680 - val_acc: 0.9394\n",
      "Epoch 11/100\n",
      "1/8 [==>...........................] - ETA: 1s - loss: 0.0737 - acc: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-094c5e138a84>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     47\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m                         workers=4)\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     model.fit_generator(datagen.flow(X_train, Y_train, batch_size=batch_size),\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[0;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m                                             class_weight=class_weight)\n\u001b[0m\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1217\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1397\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1398\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1399\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1400\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1401\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        # randomly shift images horizontally (fraction of total width)\n",
    "        width_shift_range=0.1,\n",
    "        # randomly shift images vertically (fraction of total height)\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.,  # set range for random shear\n",
    "        zoom_range=0.,  # set range for random zoom\n",
    "        channel_shift_range=0.,  # set range for random channel shifts\n",
    "        # set mode for filling points outside the input boundaries\n",
    "        fill_mode='nearest',\n",
    "        cval=0.,  # value used for fill_mode = \"constant\"\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False,  # randomly flip images\n",
    "        # set rescaling factor (applied before any other transformation)\n",
    "        rescale=None,\n",
    "        # set function that will be applied on each input\n",
    "        preprocessing_function=None,\n",
    "        # image data format, either \"channels_first\" or \"channels_last\"\n",
    "        data_format=None,\n",
    "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "        validation_split=0.0)\n",
    "\n",
    "    # Compute quantities required for feature-wise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                        steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        workers=4)\n",
    "\n",
    "    model.fit_generator(datagen.flow(X_train, Y_train, batch_size=batch_size),\n",
    "                        steps_per_epoch=X_train.shape[0] // batch_size,\n",
    "                        validation_data=(X_test, Y_test),\n",
    "                        epochs=nb_epoch, verbose=1, max_q_size=100,\n",
    "                        shuffle=True,\n",
    "                        callbacks=[lr_reducer, early_stopper, csv_logger])\n",
    "    \n",
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)\n",
    "\n",
    "# Score trained model.\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x238af997208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<matplotlib.image.AxesImage at 0x238afa20198>, None)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as  plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.imshow(x_test[2]),plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0.], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
