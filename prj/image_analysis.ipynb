{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ヒートマップ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "ja"
   },
   "source": [
    "ヒートマップをプロットするための基本的な考え方は、特定のイベントの確率に関するフィードバックを視覚的に取得することである。\n",
    "\n",
    "範囲0〜1の確率をとり、範囲（255、0、 0） - （0、0、255）またはOpencvはカラーマップを提供している。 COLORMAP _JETを使用することに興味があるかもしれません。\n",
    "\n",
    "そして今、あなたは0-1の代わりに0-255の範囲で確率を正規化しなければなりません、そしてあなたは希望する出力を得るためにcv2.applyColorMap（input_ prob、cv2.COLORMAP_JET）を使うかもしれません。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple-Python-heatmap\n",
    "\n",
    "[link](https://github.com/Muhamob/Simple-Python-heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "start = 1\n",
    "duration = 10\n",
    "fps = '30'\n",
    "cap = cv2.VideoCapture(0)\n",
    "outfile = 'heatmap.mp4'\n",
    "\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        _, f = cap.read()\n",
    "        f = cv2.cvtColor(f, cv2.COLOR_BGR2GRAY)\n",
    "        f = cv2.GaussianBlur(f, (11, 11), 2, 2)\n",
    "        cnt = 0\n",
    "        res = 0.05*f\n",
    "        res = res.astype(np.float64)\n",
    "        break\n",
    "    except:\n",
    "\n",
    "fgbg = cv2.createBackgroundSubtractorMOG2(history=1, varThreshold=100,\n",
    "                                          detectShadows=True)\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('output.avi', fourcc, 20.0, (640, 480))\n",
    "\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (13, 13))\n",
    "cnt = 0\n",
    "sec = 0\n",
    "while True:\n",
    "\n",
    "    cnt += 1\n",
    "    if cnt % int(fps) == 0:\n",
    "        print(sec)\n",
    "        sec += 1\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    fgmask = fgbg.apply(frame, None, 0.01)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (11, 11), 2, 2)\n",
    "    gray = gray.astype(np.float64)\n",
    "    fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_CLOSE, kernel)\n",
    "    fgmask = fgmask.astype(np.float64)\n",
    "    res += (40 * fgmask + gray) * 0.01\n",
    "    res_show = res / res.max()\n",
    "    res_show = np.floor(res_show * 255)\n",
    "    res_show = res_show.astype(np.uint8)\n",
    "    res_show = cv2.applyColorMap(res_show, cv2.COLORMAP_JET)\n",
    "    cv2.imshow('s', res_show)\n",
    "    out.write(frame)\n",
    "\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 物体追跡"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenCVでの密なオプティカルフロー\n",
    "\n",
    "Lucas-Kanade法が出力するオプティカルフローは疎な特徴である(上記のコードではShi-Tomasiアルゴリズムによってコーナーを検出している)。\n",
    "\n",
    "OpenCVは密なオプティカルフローを検出するためのアルゴリズムを別に用意している。画像中の全画素に対してオプティカルフローを計算する。Gunner Farnebackが2003年に発表した “Two-Frame Motion Estimation Based on Polynomial Expansion” で提案されたアルゴリズムに基づいている。\n",
    "\n",
    "以下のサンプルはこのアルゴリズムを使って密なオプティカルフローを計算している。出力として，オプティカルフローベクトル (u,v) を格納した2チャンネルの配列が返ってくる。オプティカルフローの強度と方向を計算し、カラーコード化した画像を下に示す。\n",
    "方向はHue成分，強度はValue成分によって表わしている。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "cap = cv2.VideoCapture('vtest.avi')\n",
    "\n",
    "ret, frame1 = cap.read()\n",
    "prvs = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "hsv = np.zeros_like(frame1)\n",
    "hsv[..., 1] = 255\n",
    "\n",
    "while(1):\n",
    "    ret, frame2 = cap.read()\n",
    "    next = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    flow = cv2.calcOpticalFlowFarneback(\n",
    "        prvs, next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "\n",
    "    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "#     hsv[..., 0] = ang*180/np.pi/2\n",
    "#     hsv[..., 2] = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX)\n",
    "#     rgb = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    # 0を除く最小値の1.5倍まで0にする\n",
    "    res_show = mag / mag.max()\n",
    "    res_show = np.floor(res_show * 255)\n",
    "    res_show = res_show.astype(np.uint8)\n",
    "    res_show = cv2.applyColorMap(res_show, cv2.COLORMAP_JET)\n",
    "\n",
    "    alpha = 0.6\n",
    "    res_show = cv2.addWeighted(frame2, alpha, res_show, 1 - alpha, 0)\n",
    "\n",
    "    cv2.imshow('blend', res_show)\n",
    "#     cv2.imshow('frame2', frame2)\n",
    "    k = cv2.waitKey(79) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "    elif k == ord('s'):\n",
    "        cv2.imwrite('opticalfb.png', frame2)\n",
    "        cv2.imwrite('opticalhsv.png', rgb)\n",
    "    prvs = next\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# サンプルコード"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QT douga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shinkawa\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3304: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from PyQt5 import QtCore, QtGui, QtWidgets\n",
    "import cv2\n",
    "import os, zipfile, datetime\n",
    "now = datetime.datetime.now()\n",
    "dirname = 'test_{0:%Y%m%d}'.format(now)\n",
    "\n",
    "class QtCapture(QtWidgets.QWidget):\n",
    "    def __init__(self, *args):\n",
    "        super(QtWidgets.QWidget, self).__init__()\n",
    "\n",
    "        self.fps = 24\n",
    "        self.cap = cv2.VideoCapture(*args)\n",
    "\n",
    "        self.video_frame = QtWidgets.QLabel()\n",
    "        lay = QtWidgets.QVBoxLayout()\n",
    "        lay.setContentsMargins(0,0,0,0)\n",
    "        lay.addWidget(self.video_frame)\n",
    "        self.setLayout(lay)\n",
    "\n",
    "        # ------ Modification ------ #\n",
    "        self.isCapturing = False\n",
    "        self.ith_frame = 1\n",
    "        # ------ Modification ------ #\n",
    "\n",
    "    def setFPS(self, fps):\n",
    "        self.fps = fps\n",
    "\n",
    "    def nextFrameSlot(self):\n",
    "        ret, frame = self.cap.read()\n",
    "\n",
    "        # ------ Modification ------ #\n",
    "        # Save images if isCapturing\n",
    "        if self.isCapturing:\n",
    "            if not(os.path.isdir(dirname)):\n",
    "                os.mkdir(dirname)\n",
    "            cv2.imwrite('./'+dirname+'/img_%05d.jpg'%self.ith_frame, frame)\n",
    "            self.ith_frame += 1\n",
    "        # ------ Modification ------ #\n",
    "\n",
    "        # My webcam yields frames in BGR format\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        img = QtGui.QImage(frame, frame.shape[1], frame.shape[0], QtGui.QImage.Format_RGB888)\n",
    "        pix = QtGui.QPixmap.fromImage(img)\n",
    "        self.video_frame.setPixmap(pix)\n",
    "\n",
    "    def start(self):\n",
    "        self.timer = QtCore.QTimer()\n",
    "        self.timer.timeout.connect(self.nextFrameSlot)\n",
    "        self.timer.start(1000./self.fps)\n",
    "\n",
    "    def stop(self):\n",
    "        self.timer.stop()\n",
    "\n",
    "    # ------ Modification ------ #\n",
    "    def capture(self):\n",
    "        if not self.isCapturing:\n",
    "            self.isCapturing = True\n",
    "        else:\n",
    "            self.isCapturing = False\n",
    "    # ------ Modification ------ #\n",
    "\n",
    "    def deleteLater(self):\n",
    "        self.cap.release()\n",
    "        super(QtWidgets.QWidget, self).deleteLater()\n",
    "\n",
    "\n",
    "class ControlWindow(QtWidgets.QWidget):\n",
    "    def __init__(self):\n",
    "        QtWidgets.QWidget.__init__(self)\n",
    "        self.capture = None\n",
    "\n",
    "        self.start_button = QtWidgets.QPushButton('Start')\n",
    "        self.start_button.clicked.connect(self.startCapture)\n",
    "        self.quit_button = QtWidgets.QPushButton('End')\n",
    "        self.quit_button.clicked.connect(self.endCapture)\n",
    "        self.end_button = QtWidgets.QPushButton('Stop')\n",
    "\n",
    "        # ------ Modification ------ #\n",
    "        self.capture_button = QtWidgets.QPushButton('Capture')\n",
    "        self.capture_button.clicked.connect(self.saveCapture)\n",
    "        # ------ Modification ------ #\n",
    "\n",
    "        vbox = QtWidgets.QVBoxLayout(self)\n",
    "        vbox.addWidget(self.start_button)\n",
    "        vbox.addWidget(self.end_button)\n",
    "        vbox.addWidget(self.quit_button)\n",
    "\n",
    "        # ------ Modification ------ #\n",
    "        vbox.addWidget(self.capture_button)\n",
    "        # ------ Modification ------ #\n",
    "\n",
    "        self.setLayout(vbox)\n",
    "        self.setWindowTitle('Control Panel')\n",
    "        self.setGeometry(100,100,200,200)\n",
    "        self.show()\n",
    "\n",
    "    def startCapture(self):\n",
    "        if not self.capture:\n",
    "            self.capture = QtCapture(0)\n",
    "            self.end_button.clicked.connect(self.capture.stop)\n",
    "            # self.capture.setFPS(1)\n",
    "            self.capture.setParent(self)\n",
    "            self.capture.setWindowFlags(QtCore.Qt.Tool)\n",
    "        self.capture.start()\n",
    "        self.capture.show()\n",
    "\n",
    "    def endCapture(self):\n",
    "        self.capture.deleteLater()\n",
    "        self.capture = None\n",
    "\n",
    "    # ------ Modification ------ #\n",
    "    def saveCapture(self):\n",
    "        if self.capture:\n",
    "            self.capture.capture()\n",
    "    # ------ Modification ------ #\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    import sys\n",
    "    app = QtWidgets.QApplication(sys.argv)\n",
    "    window = ControlWindow()\n",
    "    sys.exit(app.exec_())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# その他"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Anacondaにプロキシ設定をする"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Anacondaのルートフォルダに.condarcファイルを作成する。\n",
    "\n",
    "- ルートフォルダ環境によって異なるが、下記のいずれになります。\n",
    " - C:\\Users[ユーザー名]\\Anaconda3\n",
    " - C:\\Program Files\\Anaconda3\n",
    " - C:\\Users[ユーザー名]\\AppData\\Local\\Continuum\\anaconda3\n",
    "\n",
    "エクスプローラーから直接「.condarc」ファイルを作成できないので、 \n",
    "先に「condarc」を作成し、コマンドラインでファイル名を.condarc変更する。\n",
    "\n",
    "ren condarc .condarc\n",
    "\n",
    "- .condarcをお好みのテキストエディタで編集し、プロキシの設定を追記します。  \n",
    "\n",
    "    proxy_servers: http: http://[プロキシアドレス]:[ポート番号] https: https://[プロキシアドレス]:[ポート番号] \n",
    "    \n",
    "\n",
    "- コマンドラインから以下のコマンドで設定内容を確認できます。  \n",
    "\n",
    "   conda config --show  \n",
    "   \n",
    "\n",
    "- proxy_serversのところに正しいプロキシであれば設定完了です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nbTranslate": {
   "displayLangs": [
    "ja"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "ja",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
